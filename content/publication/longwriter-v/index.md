---
title: 'LongWriter-V: Enabling Ultra-Long and High-Fidelity Generation in Vision-Language Models'
authors:
- Shangqing Tu
- Yucheng Wang
- Daniel Zhang-Li
- Yushi Bai
- Jifan Yu
- Yuhao Wu
- Lei Hou
- Huiqin Liu
- Zhiyuan Liu
- Bin Xu
- Juanzi Li
date: '2025-01-01'
publication_types:
- paper-conference
publication: 'ACM MM 2025'
abstract: 'Vision-language models have made remarkable progress in generating text from images, but generating lengthy, detailed descriptions with high fidelity remains challenging. We present LongWriter-V, a novel framework that enables vision-language models to produce ultra-long, high-fidelity textual descriptions from visual inputs. Our approach combines hierarchical visual understanding with structured text generation, allowing the model to capture fine-grained visual details while maintaining global coherence across extended outputs. LongWriter-V employs a region-aware attention mechanism that ensures comprehensive coverage of visual content and introduces a multi-stage verification process to maintain factual accuracy throughout long-form generation. Extensive experiments on image captioning, visual storytelling, and detailed image analysis tasks demonstrate that LongWriter-V significantly outperforms existing methods, generating coherent, accurate descriptions exceeding 1000 words while preserving visual-textual alignment and factual correctness.'
image:
  preview_only: true
links:
  - name: arXiv
    url: https://arxiv.org/abs/2501.15206
  - name: PDF
    url: https://arxiv.org/pdf/2501.15206.pdf
  - name: Google Scholar
    url: https://scholar.google.com/scholar?q=LongWriter-V%3A%20Enabling%20Ultra-Long%20and%20High-Fidelity%20Generation%20in%20Vision-Language%20Models
---


